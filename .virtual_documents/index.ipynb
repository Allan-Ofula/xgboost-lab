


from xgboost import XGBClassifier





import pandas as pd
import numpy as np
np.random.seed(0)
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')
get_ipython().run_line_magic("matplotlib", " inline")





df = pd.read_csv('winequality-red.csv')

df.head()





y = df['quality']
X = df.drop('quality', axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)





y_train.value_counts().sort_index()





# Instantiate the encoder
encoder = LabelEncoder()

# Fit and transform the training data
y_train = encoder.fit_transform(y_train)

# Transform the test data
y_test = encoder.transform(y_test)





# Your code here to inspect the values of y_train and y_test

# Inspecting the encoded values
print("Encoded y_train classes:", np.unique(y_train))
print("Encoded y_test classes:", np.unique(y_test))





# Instantiate XGBClassifier
clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')

# Fit XGBClassifier
clf.fit(X_train, y_train)

# Predict on training and test sets
training_preds = clf.predict(X_train)
test_preds = clf.predict(X_test)

# Accuracy of training and test sets
training_accuracy = accuracy_score(y_train, training_preds)
test_accuracy = accuracy_score(y_test, test_preds)

print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))
print('Validation accuracy: {:.4}%'.format(test_accuracy * 100))





param_grid = {
    'learning_rate': [0.1, 0.2],
    'max_depth': [6],
    'min_child_weight': [1, 2],
    'subsample': [0.5, 0.7],
    'n_estimators': [100],
}





# Creating GridSearchCV object

grid_clf = GridSearchCV(
    estimator=XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),
    param_grid=param_grid,
    scoring='accuracy',
    cv=None,
    n_jobs=1
)

# Fitting the model
grid_clf.fit(X_train, y_train)

best_parameters = grid_clf.best_params_

print('Grid Search found the following optimal parameters: ')
for param_name in sorted(best_parameters.keys()):
    print('%s: %r' % (param_name, best_parameters[param_name]))

# Predictions using best model
training_preds = grid_clf.predict(X_train)
test_preds = grid_clf.predict(X_test)

# Accuracy scores
training_accuracy = accuracy_score(y_train, training_preds)
test_accuracy = accuracy_score(y_test, test_preds)

print('')
print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))
print('Validation accuracy: {:.4}%'.format(test_accuracy * 100))



